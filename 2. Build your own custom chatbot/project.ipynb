{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124e5672",
   "metadata": {},
   "source": [
    "# Custom Chatbot Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf99f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = 'voc-2142092199126677363517367290fc6838ea0.15892753'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a94b3",
   "metadata": {},
   "source": [
    "TODO: In this cell, write an explanation of which dataset you have chosen and why it is appropriate for this task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb50954",
   "metadata": {},
   "source": [
    "- For this project, I have utilized the dataset \"2023_fashion_trends.csv,\" which is available in the \"data\" folder of the Udacity workspace. The primary objective of this project is to demonstrate the application of a custom dataset with a large language model (LLM) using a technique known as Retrieval-Augmented Generation (RAG).\n",
    "- This dataset is particularly suitable for our purposes because it provides up-to-date information on fashion trends from 2023, whereas the OpenAI model \"gpt-3.5-turbo-instruct\" has a knowledge cutoff date of 2022. By incorporating this more recent dataset, we can effectively showcase the benefits of using RAG with an LLM. RAG allows the model to augment its responses by retrieving relevant, context-specific data from an external source—such as this 2023 dataset—thereby enhancing its ability to provide more accurate, current, and insightful responses.\n",
    "- In summary, leveraging the \"2023_fashion_trends.csv\" dataset aligns perfectly with the goal of illustrating the power of RAG in overcoming the knowledge limitations of pre-trained models, especially those with outdated training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63d4c5f",
   "metadata": {},
   "source": [
    "## Data Wrangling\n",
    "\n",
    "TODO: In the cells below, load your chosen dataset into a `pandas` dataframe with a column named `\"text\"`. This column should contain all of your text data, separated into at least 20 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b83a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a595980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb3a9fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae769871",
   "metadata": {},
   "source": [
    "## Custom Query Completion\n",
    "\n",
    "TODO: In the cells below, compose a custom query using your chosen dataset and retrieve results from an OpenAI `Completion` model. You may copy and paste any useful code from the course materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582f0656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e1f75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f2dcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403f543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74280b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1783f146",
   "metadata": {},
   "source": [
    "## Custom Performance Demonstration\n",
    "\n",
    "TODO: In the cells below, demonstrate the performance of your custom query using at least 2 questions. For each question, show the answer from a basic `Completion` model query as well as the answer from your custom query."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11fdc0",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901c850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7a093b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e86e37c",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f646989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c07a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
